{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccf3ecf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## THIS IS THE CODE PROVIDED IN THE LAB SESSION FROM LECTURER ##\n",
    "import tensorrt as trt\n",
    "from tensorrt_model import TRTModel\n",
    "from ssd_tensorrt import load_plugins, parse_boxes,TRT_INPUT_NAME, TRT_OUTPUT_NAME\n",
    "import ctypes\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import ctypes\n",
    "    \n",
    "mean = 255.0 * np.array([0.5, 0.5, 0.5])\n",
    "stdev = 255.0 * np.array([0.5, 0.5, 0.5])\n",
    "\n",
    "def bgr8_to_ssd_input(camera_value):\n",
    "    x = camera_value\n",
    "    x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)\n",
    "    x = x.transpose((2, 0, 1)).astype(np.float32)\n",
    "    x -= mean[:, None, None]\n",
    "    x /= stdev[:, None, None]\n",
    "    return x[None, ...]\n",
    "\n",
    "class ObjectDetector(object):\n",
    "    \n",
    "    def __init__(self, engine_path, preprocess_fn=bgr8_to_ssd_input):\n",
    "        logger = trt.Logger()\n",
    "        trt.init_libnvinfer_plugins(logger, '')\n",
    "        load_plugins()\n",
    "        self.trt_model = TRTModel(engine_path, input_names=[TRT_INPUT_NAME],output_names=[TRT_OUTPUT_NAME, TRT_OUTPUT_NAME + '_1'])\n",
    "        self.preprocess_fn = preprocess_fn\n",
    "\n",
    "    def execute(self, *inputs):\n",
    "        trt_outputs = self.trt_model(self.preprocess_fn(*inputs))\n",
    "        return parse_boxes(trt_outputs)\n",
    "    def __call__(self, *inputs):\n",
    "        return self.execute(*inputs)\n",
    "\n",
    "model = ObjectDetector('ssd_mobilenet_v2_coco.engine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f6ba04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use traitlets and widgets to display the image in Jupyter Notebook\n",
    "import traitlets\n",
    "from traitlets.config.configurable import SingletonConfigurable\n",
    "\n",
    "#use opencv to covert the depth image to RGB image for displaying purpose\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "#using realsense to capture the color and depth image\n",
    "import pyrealsense2 as rs\n",
    "\n",
    "#multi-threading is used to capture the image in real time performance\n",
    "import threading\n",
    "\n",
    "class Camera(SingletonConfigurable):\n",
    "    \n",
    "    #this changing of this value will be captured by traitlets\n",
    "    color_value = traitlets.Any()\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Camera, self).__init__()\n",
    "        \n",
    "        self.warning_flag=0\n",
    "        #configure the color and depth sensor\n",
    "        self.pipeline = rs.pipeline()\n",
    "        self.configuration = rs.config()  \n",
    "        \n",
    "        #set resolution for the color camera\n",
    "        self.color_width = 640\n",
    "        self.color_height = 480\n",
    "        self.color_fps = 30\n",
    "        self.configuration.enable_stream(rs.stream.color, self.color_width, self.color_height, rs.format.bgr8, self.color_fps)\n",
    "\n",
    "        #set resolution for the depth camera\n",
    "        self.depth_width = 640\n",
    "        self.depth_height = 480\n",
    "        self.depth_fps = 30\n",
    "        self.configuration.enable_stream(rs.stream.depth, self.depth_width, self.depth_height, rs.format.z16, self.depth_fps)\n",
    "\n",
    "        #flag to control the thread\n",
    "        self.thread_runnning_flag = False\n",
    "        \n",
    "        #start the RGBD sensor\n",
    "        self.pipeline.start(self.configuration)\n",
    "        self.pipeline_started = True\n",
    "        frames = self.pipeline.wait_for_frames()\n",
    "\n",
    "        #start capture the first color image\n",
    "        color_frame = frames.get_color_frame()   \n",
    "        image = np.asanyarray(color_frame.get_data())\n",
    "        self.color_value = image\n",
    "\n",
    "        #start capture the first depth image\n",
    "        depth_frame = frames.get_depth_frame()           \n",
    "        depth_image = np.asanyarray(depth_frame.get_data())\n",
    "        depth_colormap = cv2.applyColorMap(cv2.convertScaleAbs(depth_image, alpha=0.03), cv2.COLORMAP_JET)\n",
    "        self.depth_value = depth_colormap   \n",
    "\n",
    "    def _capture_frames(self):\n",
    "        while(self.thread_runnning_flag==True): #continue until the thread_runnning_flag is set to be False\n",
    "            frames = self.pipeline.wait_for_frames() #receive data from RGBD sensor\n",
    "            \n",
    "            color_frame = frames.get_color_frame() #get the color image\n",
    "            image = np.asanyarray(color_frame.get_data()) #convert color image to numpy array\n",
    "            self.color_value = image #assign the numpy array image to the color_value variable \n",
    "\n",
    "            depth_frame = frames.get_depth_frame() #get the depth image           \n",
    "            depth_image = np.asanyarray(depth_frame.get_data()) #convert depth data to numpy array\n",
    "                \n",
    "            #we only consider the central area of the vision sensor\n",
    "            depth_image[:190,:]=0\n",
    "            depth_image[290:,:]=0\n",
    "            depth_image[:,:160]=0\n",
    "            depth_image[:,480:]=0\n",
    "            \n",
    "            #For object avoidance, we don't consider the distance that are lower than 100mm or bigger than 1000mm\n",
    "            depth_image[depth_image<100]=0\n",
    "            depth_image[depth_image>1000]=0\n",
    "            \n",
    "            #If all of the values in the depth image is 0, the depth[depth!=0] command will fail\n",
    "            #we set a specific value here to prevent this failure\n",
    "            depth_image[0,0]=2000\n",
    "            \n",
    "            depth_colormap = cv2.applyColorMap(cv2.convertScaleAbs(depth_image, alpha=0.03), cv2.COLORMAP_JET)\n",
    "            if (depth_image[depth_image!=0].min()<400):\n",
    "                self.warning_flag=1\n",
    "            else:\n",
    "                self.warning_flag=0\n",
    "            self.depth_value = depth_colormap #assign the color BGR image to the depth value\n",
    "               \n",
    "    def start(self): #start the data capture thread\n",
    "        if self.thread_runnning_flag == False: #only process if no thread is running yet\n",
    "            self.thread_runnning_flag=True #flag to control the operation of the _capture_frames function\n",
    "            self.thread = threading.Thread(target=self._capture_frames) #link thread with the function\n",
    "            self.thread.start() #start the thread\n",
    "\n",
    "    def stop(self): #stop the data capture thread\n",
    "        if self.thread_runnning_flag == True:\n",
    "            self.thread_runnning_flag = False #exit the while loop in the _capture_frames\n",
    "            self.thread.join() #wait the exiting of the thread       \n",
    "\n",
    "def bgr8_to_jpeg(value):#convert numpy array to jpeg coded data for displaying \n",
    "    return bytes(cv2.imencode('.jpg',value)[1])\n",
    "\n",
    "#create a camera object\n",
    "camera = Camera.instance()\n",
    "camera.start() # start capturing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "270c5877",
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_mode = False # Initial attack_mode is false\n",
    "love_mode = False # Initial love_mode is false\n",
    "fear_mode = False # Initial fear_mode is false\n",
    "curious_mode = False # Initial curious_mode is false\n",
    "\n",
    "def stop_all_behaviour():\n",
    "    \n",
    "    \"\"\" This functions is created to make all the behaviours mode inactive.\n",
    "    \"\"\"\n",
    "    global attack_mode, love_mode, fear_mode, curious_mode\n",
    "    #All the modes are set the false\n",
    "    \n",
    "    attack_mode = False\n",
    "    love_mode = False\n",
    "    fear_mode = False\n",
    "    curious_mode = False\n",
    "    \n",
    "    robot.stop()#Robot will stop if it is moving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d81e62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def love_behaviour(matching_detections,image):\n",
    "    \n",
    "    \"\"\" This function is created to give robot love behaviour.\n",
    "    \"\"\"\n",
    "    \n",
    "    global love_mode # Function uses global love_mode variable\n",
    "    \n",
    "    if love_mode: # Check if the robot is in love mode\n",
    "        largest = [] # initial largest [area, startx, starty , endx, endy]\n",
    "        leftarea , rightarea =0,0 # Initial left and right areas are set to zero\n",
    "\n",
    "        for det in matching_detections: # Loop is created to detech all target objects\n",
    "            bbox = det['bbox'] # Get detected box\n",
    "            #Created blue box around the object\n",
    "            cv2.rectangle(image, (int(width * bbox[0]), int(height * bbox[1])),\n",
    "                          (int(width * bbox[2]), int(height * bbox[3])), (255, 0, 0), 2)\n",
    "            startx = int(width * bbox[0])#Take start x point\n",
    "            starty = int(height * bbox[1])#Take start y point\n",
    "            endx   = int(width * bbox[2])#Take end x point\n",
    "            endy   = int(height * bbox[3])#Take end y point\n",
    "            area   = abs(endx - startx) * abs(endy - starty)#Calculate the area\n",
    "            \n",
    "            #If the area bigger then previous take this one as largest\n",
    "            if len(largest) == 0 or area > largest[0]: \n",
    "                largest = [area, startx, starty, endx, endy] # Make it new largest area.\n",
    "\n",
    "        try: #To avoid fails try statement is added\n",
    "            if largest[3] < 320 : # If even end of x is smaller then middle point of the screen.\n",
    "                leftarea = largest[0] # The left area will be all of the objects area.\n",
    "                rightarea = 0 # There is going to be nothing in the left side.\n",
    "            elif largest[1] >320 : # If even start of x is bigger then middle point of the screen.\n",
    "                rightarea= largest[0] # The right area will be all of the objects area.\n",
    "                leftarea = 0 # There is going to be nothing in the right side.\n",
    "            elif largest[3] > 320 and largest[1] < 320: # If object is middle of the screen\n",
    "                # Calculate how much of the object is in the left area\n",
    "                leftarea = abs(largest[4] - largest[2]) * abs((width/2)-largest[1])\n",
    "                # Calculate how much of the object is in the right area\n",
    "                rightarea = abs(largest[4] - largest[2]) * abs(largest[3]-(width/2))\n",
    "        except:# If there is any fail\n",
    "            pass # Pass the statement\n",
    "\n",
    "\n",
    "        if len(matching_detections)==0 or camera.warning_flag == 1:\n",
    "            # If there is nothing detected or robot is to close to any object\n",
    "            robot.stop()# Robot will stop\n",
    "            \n",
    "        else:# If there is no condition like defined up there\n",
    "            \n",
    "            if rightarea > leftarea *3: # If most of size of the object in the right side.\n",
    "\n",
    "                \n",
    "                robot.forward_right(0.7) # Robot will move forward right side with 0.7 speed.\n",
    "                time.sleep(0.2) # Make this move for 0.2 second\n",
    "\n",
    "            elif leftarea > rightarea *3: # If most of size of the object in the left side.\n",
    "\n",
    "    \n",
    "                robot.forward_left(0.7) # Robot will move forward right side with 0.7 speed.\n",
    "                time.sleep(0.2) # Make this move for 0.2 second\n",
    "\n",
    "            else: # If none of the area is bigger than other.\n",
    "\n",
    "                robot.forward(0.4) # Go forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df41d4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def agressive_behaviour(matching_detections,image):\n",
    " \n",
    "    \"\"\" This function is created to give robot aggressive behaviour.\n",
    "    \"\"\"\n",
    "\n",
    "    global attack_mode # Function uses global attack_mode variable\n",
    "    \n",
    "    if attack_mode: # Check if the robot is in attack_mode\n",
    "\n",
    "        largest = [] # initial largest [area, startx, starty , endx, endy]\n",
    "        leftarea , rightarea =0,0 # Initial left and right areas are set to zero\n",
    "\n",
    "        for det in matching_detections: # Loop is created to detech all target objects\n",
    "            bbox = det['bbox'] # Get detected box\n",
    "            #Created blue box around the object\n",
    "            cv2.rectangle(image, (int(width * bbox[0]), int(height * bbox[1])),\n",
    "                          (int(width * bbox[2]), int(height * bbox[3])), (255, 0, 0), 2)\n",
    "            \n",
    "            startx = int(width * bbox[0]) #Take start x point\n",
    "            starty = int(height * bbox[1]) #Take start y point\n",
    "            endx   = int(width * bbox[2]) #Take end x point\n",
    "            endy   = int(height * bbox[3]) #Take end y point\n",
    "            area   = abs(endx - startx) * abs(endy - starty) #Calculate the area\n",
    "\n",
    "            #If the area bigger then previous take this one as largest\n",
    "            if len(largest) == 0 or area > largest[0]:\n",
    "                largest = [area, startx, starty, endx, endy] # Make it new largest area.\n",
    "\n",
    "        try: #To avoid fails try statement is added\n",
    "            if largest[3] < 320 :# If even end of x is smaller then middle point of the screen.\n",
    "                leftarea = largest[0] # The left area will be all of the objects area.\n",
    "                rightarea = 0 # There is going to be nothing in the left side.\n",
    "            elif largest[1] >320 : # If even start of x is bigger then middle point of the screen.\n",
    "                rightarea= largest[0] # The right area will be all of the objects area.\n",
    "                leftarea = 0  # There is going to be nothing in the right side.\n",
    "            elif largest[3] > 320 and largest[1] < 320:# If object is middle of the screen\n",
    "                # Calculate how much of the object is in the left area\n",
    "                leftarea = abs(largest[4] - largest[2]) * abs((width/2)-largest[1])\n",
    "                # Calculate how much of the object is in the right area\n",
    "                rightarea = abs(largest[4] - largest[2]) * abs(largest[3]-(width/2))\n",
    "        except:# If there is any fail\n",
    "            pass # Pass the statement\n",
    "\n",
    "        # If there is no object which is looking for or any object.\n",
    "        if len(matching_detections)==0 and camera.warning_flag == 0:\n",
    "            \n",
    "            robot.left(0.4)#keep turning to find one.\n",
    "        # If there is no object which is looking for and a another object in front of robot.    \n",
    "        elif len(matching_detections)==0: \n",
    "            \n",
    "            robot.stop()# Robot will stop.\n",
    "            \n",
    "        else: # If robot see target object\n",
    "            \n",
    "            if camera.warning_flag == 1: # If robot is close enough to the object.\n",
    "                \n",
    "                time.sleep(0.3)# Keep moving forward to go closer target ebject for 0.3 second\n",
    "                robot.backward(0.7) # Go back\n",
    "                time.sleep(0.7)# Wait 0.7 seconds\n",
    "                robot.stop()# Stop in there\n",
    "                robot.forward(0.7) # Go forward to the target again\n",
    "                time.sleep(0.7)#Go for 0.7 seconds\n",
    "                robot.stop()#Stop in there\n",
    "                attack_mode = False# Change the attack mode with false to finish behaviour.\n",
    "                stop_all_behaviour() # Stop all behaviours to have new command.\n",
    "\n",
    "            elif rightarea > leftarea *3 : # If most of size of the object in the right side.\n",
    "\n",
    "                robot.forward_right(0.8) # Robot will move forward right side with 0.8 speed.\n",
    "                time.sleep(0.2)# Make this move for 0.2 second\n",
    "\n",
    "            elif leftarea > rightarea *3: # If most of size of the object in the left side.\n",
    "\n",
    "                robot.forward_left(0.8)  # Robot will move forward right side with 0.8 speed.\n",
    "                time.sleep(0.2)# Make this move for 0.2 second\n",
    "\n",
    "            else: # If none of the area is bigger than other.\n",
    "\n",
    "                robot.forward(0.4) # Go forward.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8292cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def curious_behaviour(matching_detections,image):\n",
    "    \n",
    "    \"\"\" This function is created to give robot curious behaviour.\n",
    "    \"\"\"    \n",
    "    \n",
    "    global curious_mode # Function uses global curios_mode variable\n",
    "    \n",
    "    if curious_mode : # Check if the robot is in curious_mode\n",
    "\n",
    "        largest = [] # initial largest [area, startx, starty , endx, endy]\n",
    "        leftarea , rightarea =0,0 # Initial left and right areas are set to zero\n",
    "\n",
    "        for det in matching_detections: # Loop is created to detech all target objects\n",
    "            bbox = det['bbox']# Get detected box\n",
    "            #Created blue box around the object\n",
    "            cv2.rectangle(image, (int(width * bbox[0]), int(height * bbox[1])),\n",
    "                          (int(width * bbox[2]), int(height * bbox[3])), (255, 0, 0), 2)\n",
    "            startx = int(width * bbox[0])#Take start x point\n",
    "            starty = int(height * bbox[1])#Take start y point\n",
    "            endx   = int(width * bbox[2])#Take end x point\n",
    "            endy   = int(height * bbox[3])#Take end y point\n",
    "            area   = abs(endx - startx) * abs(endy - starty)#Calculate the area\n",
    "\n",
    "            #If the area bigger then previous take this one as largest\n",
    "            if len(largest) == 0 or area > largest[0]:\n",
    "                \n",
    "                largest = [area, startx, starty, endx, endy]# Make it new largest area.\n",
    "\n",
    "        try: #To avoid fails try statement is added\n",
    "            if largest[3] < 320 : # If even end of x is smaller then middle point of the screen.\n",
    "                leftarea = largest[0] # The left area will be all of the objects area.\n",
    "                rightarea = 0 # There is going to be nothing in the left side.\n",
    "            elif largest[1] >320 : # If even start of x is bigger then middle point of the screen.\n",
    "                rightarea= largest[0] # The right area will be all of the objects area.\n",
    "                leftarea = 0 # There is going to be nothing in the right side.\n",
    "            elif largest[3] > 320 and largest[1] < 320: # If object is middle of the screen\n",
    "                # Calculate how much of the object is in the left area\n",
    "                leftarea = abs(largest[4] - largest[2]) * abs((width/2)-largest[1])\n",
    "                # Calculate how much of the object is in the right area\n",
    "                rightarea = abs(largest[4] - largest[2]) * abs(largest[3]-(width/2))\n",
    "        except:# If there is any fail\n",
    "            pass# Pass the statement\n",
    "\n",
    "\n",
    "        # If there is no object which is looking for or any object.\n",
    "        if len(matching_detections)==0 and camera.warning_flag == 0:\n",
    "            \n",
    "            robot.left(0.4)#keep turning to find one.\n",
    "        # If there is no object which is looking for and a another object in front of robot.    \n",
    "        elif len(matching_detections)==0: \n",
    "            \n",
    "            robot.stop()# Robot will stop.\n",
    "            \n",
    "        else: # If robot see target object\n",
    "            \n",
    "            if camera.warning_flag == 1: # If robot is close enough to the object.\n",
    "                \n",
    "                for _ in range(5): # Make angles changer move for five times\n",
    "                    \n",
    "                    robot.degree(80)# Turn 80 degree right\n",
    "                    time.sleep(0.5)# Wait for 0.5 second\n",
    "                    robot.forward(0.5) # Go forward for half speed\n",
    "                    time.sleep(0.5)# Wait for 0.5 second\n",
    "                    robot.degree(-85) # Tun 85 degree left\n",
    "                    time.sleep(0.5) # Wait for 0.5 second\n",
    "                    robot.stop() # Stop the robot\n",
    "                    time.sleep(1) # Wait for 1 second\n",
    "                    stop_all_behaviour() # Stop all behaviuors\n",
    "                    \n",
    "\n",
    "            elif rightarea > leftarea *3 : # If most of size of the object in the right side.\n",
    "\n",
    "                robot.forward_right(0.8) # Robot will move forward right side with 0.8 speed.\n",
    "                time.sleep(0.2)# Make this move for 0.2 second\n",
    "\n",
    "            elif leftarea > rightarea *3: # If most of size of the object in the left side.\n",
    "\n",
    "                robot.forward_left(0.8)  # Robot will move forward right side with 0.8 speed.\n",
    "                time.sleep(0.2)# Make this move for 0.2 second\n",
    "\n",
    "            else: # If none of the area is bigger than other.\n",
    "\n",
    "                robot.forward(0.4) # Go forward.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de85f1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fear_behaviour(matching_detections,image):\n",
    "    \n",
    "    \"\"\" This function is created to give robot fear behaviour.\n",
    "    \"\"\"       \n",
    "    \n",
    "    global fear_mode # Function uses global curios_mode variable\n",
    "    \n",
    "    if fear_mode: # Check if the robot is in fear_mode\n",
    "\n",
    "        # If there is no object what we fear stay there\n",
    "        if len(matching_detections)==0:\n",
    "            \n",
    "            robot.stop()# Robot will stop.\n",
    "\n",
    "        else:# If robot see object that it afraid of\n",
    "\n",
    "            robot.left(1) # Turn back\n",
    "            time.sleep(0.8)# Wait for 0.8 second\n",
    "            robot.forward(1)# Go forward for one second.\n",
    "            time.sleep(0.5)# Wait for 0.5 second\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "367da388",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import ipywidgets.widgets as widgets # ipywidgets are imported\n",
    "from IPython.display import display, HTML # display and HTML are imported\n",
    "from RobotClass import Robot # Robot library is imported\n",
    "import math # Math library is imported \n",
    "import time # TIme library is imported \n",
    "\n",
    "width = 640 # Camera screen width is set to 640\n",
    "height = 480 # Camera screen height is set to 480\n",
    "\n",
    "image_widget = widgets.Image(format='jpeg', width=300, height=300)# Initial image widget is set\n",
    "label_widget = widgets.IntText(value=1, description='tracked label')# Initial label is set to 1 which is human\n",
    "\n",
    "robot = Robot()# Robot class is created\n",
    "\n",
    "\n",
    "def processing(change):\n",
    "\n",
    "    \"\"\" This function is created to observes changes to have new dynamic values.\n",
    "    \"\"\"\n",
    "    image = change['new'] # Captures changes in the image \n",
    "    imgsized= cv2.resize(image,(300,300)) # Resize the image into 300x300\n",
    "    # compute all detected objects\n",
    "    \n",
    "    detections = model(imgsized)# Stores the detections\n",
    "    # Stores if there is any detections which matches with label value\n",
    "    matching_detections = [d for d in detections[0] if d['label'] == int(label_widget.value)]\n",
    "    \n",
    "    fear_behaviour(matching_detections, image)# Fear behaviour is applied\n",
    "    curious_behaviour(matching_detections, image)# Curious behaviour is applied\n",
    "    love_behaviour(matching_detections,image)# Love behaviour is applied\n",
    "    agressive_behaviour(matching_detections,image)# Agressive behaviour is applied\n",
    "    image_widget.value = bgr8_to_jpeg(image)# Take the image value\n",
    "    \n",
    "#the camera.observe function will monitor the color_value variable. If this value changes, the excecute function will be excuted.\n",
    "camera.observe(processing, names='color_value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "baad8ff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcd485b5b92d4418ba4eaeb4d69e275e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(description='Aggressive', style=ButtonStyle()), Button(description='Love', style=ButtonS…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab075dce5c3a4e608e1c3e909cc96790",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Image(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\x…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8a8cdbad0824e62b35dd18ab346a834",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Button(description='↖', layout=Layout(width='auto'), style=ButtonStyle()), Butto…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create robot behaviour selection and control buttons\n",
    "button_aggressive = widgets.Button(description='Aggressive')\n",
    "button_love = widgets.Button(description='Love')\n",
    "button_fear = widgets.Button(description='Fear')\n",
    "button_curious = widgets.Button(description='Curious')\n",
    "button_stop_behaviour = widgets.Button(description='Stop Behaviour', button_style='danger')\n",
    "button_up = widgets.Button(description='↑')\n",
    "button_down = widgets.Button(description='↓')\n",
    "button_left = widgets.Button(description='←')\n",
    "button_right = widgets.Button(description='→')\n",
    "button_forward_left = widgets.Button(description='↖')\n",
    "button_forward_right = widgets.Button(description='↗')\n",
    "button_stop = widgets.Button(description='Stop', button_style='danger') \n",
    "\n",
    "# styling buttons\n",
    "button_up.layout.width = 'auto'\n",
    "button_down.layout.width = 'auto'\n",
    "button_left.layout.width = 'auto'\n",
    "button_right.layout.width = 'auto'\n",
    "button_stop.layout.width = 'auto'\n",
    "button_forward_left.layout.width = 'auto'\n",
    "button_forward_right.layout.width = 'auto'\n",
    "\n",
    "#defining button functions\n",
    "\n",
    "def on_aggressive_click(b):\n",
    "\n",
    "    \"\"\" This function is created to make attack_mode is True when it is clicked.  \n",
    "    \"\"\"\n",
    "    \n",
    "    global attack_mode, love_mode, fear_mode, curious_mode\n",
    "    attack_mode = True\n",
    "    love_mode = False\n",
    "    fear_mode = False\n",
    "    curious_mode = False\n",
    "    \n",
    "def on_love_click(b):\n",
    "    \n",
    "    \"\"\" This function is created to make love_mode is True when it is clicked.  \n",
    "    \"\"\"    \n",
    "    \n",
    "    global attack_mode, love_mode, fear_mode, curious_mode\n",
    "    attack_mode = False\n",
    "    love_mode = True\n",
    "    fear_mode = False\n",
    "    curious_mode = False\n",
    "\n",
    "\n",
    "def on_fear_click(b):\n",
    "    \n",
    "    \"\"\" This function is created to make fear_mode is True when it is clicked.  \n",
    "    \"\"\"      \n",
    "    \n",
    "    global attack_mode, love_mode, fear_mode, curious_mode\n",
    "    attack_mode = False\n",
    "    love_mode = False\n",
    "    fear_mode = True\n",
    "    curious_mode = False\n",
    "\n",
    "def on_curious_click(b):\n",
    "\n",
    "    \"\"\" This function is created to make curious_mode is True when it is clicked.  \n",
    "    \"\"\"  \n",
    "    \n",
    "    global attack_mode, love_mode, fear_mode, curious_mode\n",
    "    attack_mode = False\n",
    "    love_mode = False\n",
    "    fear_mode = False\n",
    "    curious_mode = True\n",
    "    \n",
    "def on_stop_behaviour_click(b):\n",
    "    \n",
    "    \"\"\" This function is created to stop all behaviours when it is clicked.  \n",
    "    \"\"\"  \n",
    "    \n",
    "    stop_all_behaviour()\n",
    "\n",
    "    \n",
    "def on_forward_left_click(b):\n",
    "    \n",
    "    \"\"\" This function is created to move robot forward left when it is clicked.  \n",
    "    \"\"\"  \n",
    "    \n",
    "    robot.forward_left(0.5)\n",
    "    time.sleep(0.5)\n",
    "    robot.stop()\n",
    "    stop_all_behaviour()\n",
    "    \n",
    "def on_forward_click(b):\n",
    "    \n",
    "    \"\"\" This function is created to move robot forward when it is clicked.  \n",
    "    \"\"\"     \n",
    "    \n",
    "    robot.forward(0.5)\n",
    "    time.sleep(0.5)\n",
    "    robot.stop()\n",
    "    stop_all_behaviour()\n",
    "    \n",
    "    \n",
    "def on_forward_right_click(b):\n",
    "    \n",
    "    \"\"\" This function is created to move robot forward right when it is clicked.  \n",
    "    \"\"\" \n",
    "    \n",
    "    robot.forward_right(0.5)\n",
    "    time.sleep(0.5)\n",
    "    robot.stop()\n",
    "    stop_all_behaviour()\n",
    "    \n",
    "def on_left_click(b):\n",
    "    \n",
    "    \"\"\" This function is created to move robot left when it is clicked.  \n",
    "    \"\"\"     \n",
    "    \n",
    "    robot.left(0.5)\n",
    "    time.sleep(0.5)\n",
    "    robot.stop()\n",
    "    stop_all_behaviour()\n",
    "\n",
    "def on_stop_click(b):\n",
    "    robot.stop()\n",
    "    stop_all_behaviour()\n",
    "\n",
    "def on_right_click(b):\n",
    "    \n",
    "    \"\"\" This function is created to move robot right when it is clicked.  \n",
    "    \"\"\"       \n",
    "    \n",
    "    robot.right(0.5)\n",
    "    time.sleep(0.5)\n",
    "    robot.stop()\n",
    "    stop_all_behaviour()\n",
    "\n",
    "def on_backward_click(b):\n",
    "    \n",
    "    \"\"\" This function is created to move robot backward when it is clicked.  \n",
    "    \"\"\"       \n",
    "    \n",
    "    robot.backward(0.5)\n",
    "    time.sleep(0.5)\n",
    "    robot.stop()   \n",
    "    stop_all_behaviour()\n",
    "\n",
    "# Link button clicks to their respective functions\n",
    "button_aggressive.on_click(on_aggressive_click)\n",
    "button_love.on_click(on_love_click)\n",
    "button_fear.on_click(on_fear_click)\n",
    "button_curious.on_click(on_curious_click)\n",
    "button_stop_behaviour.on_click(on_stop_behaviour_click)\n",
    "\n",
    "button_forward_left.on_click(on_forward_left_click)\n",
    "button_up.on_click(on_forward_click)\n",
    "button_forward_right.on_click(on_forward_right_click)\n",
    "button_left.on_click(on_left_click)\n",
    "button_stop.on_click(on_stop_click)\n",
    "button_right.on_click(on_right_click)\n",
    "button_down.on_click(on_backward_click)\n",
    "\n",
    "# Putting buttons together to have better apperance\n",
    "button_up_fl_fr_box = widgets.HBox([button_forward_left, button_up, button_forward_right], layout=widgets.Layout(justify_content='center'))\n",
    "button_lr_stop_box = widgets.HBox([button_left, button_stop, button_right], layout=widgets.Layout(justify_content='center'))\n",
    "joystick_box = widgets.VBox([button_up_fl_fr_box, button_lr_stop_box, button_down], layout=widgets.Layout(align_items='center'))\n",
    "\n",
    "# Display buttons\n",
    "buttons_container = widgets.HBox([button_aggressive, button_love, button_fear, button_curious, button_stop_behaviour])\n",
    "display(buttons_container)\n",
    "display(widgets.VBox([widgets.HBox([image_widget,]),label_widget]))\n",
    "display(joystick_box)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cf3fa8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
